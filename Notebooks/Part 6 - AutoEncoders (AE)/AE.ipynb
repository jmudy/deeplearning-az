{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Autoencoder"],"metadata":{"id":"5_9zf3AoaQxB"}},{"cell_type":"markdown","metadata":{"id":"Hd7dRHyGk59L"},"source":["## Importar las librerías"]},{"cell_type":"code","metadata":{"id":"a-h2dwXIkt5w"},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3YsQ0VYOtoCt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699998921433,"user_tz":-60,"elapsed":26581,"user":{"displayName":"Jesús Mudarra Luján","userId":"18317898844326109750"}},"outputId":"74d791c3-2873-496d-c67d-e7ba7ab60179"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","\n","%cd \"/content/drive/MyDrive/deeplearning-az/Notebooks/Part 6 - AutoEncoders (AE)\""],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/deeplearning-az/Notebooks/Part 6 - AutoEncoders (AE)\n"]}]},{"cell_type":"markdown","metadata":{"id":"DI6WdEzbk-Za"},"source":["## Importar el dataset\n"]},{"cell_type":"code","metadata":{"id":"Xoeia18zk9jr"},"source":["movies = pd.read_csv(\"ml-1m/movies.dat\", sep=\"::\", header=None, engine=\"python\", encoding=\"latin-1\")\n","users = pd.read_csv(\"ml-1m/users.dat\", sep=\"::\", header=None, engine=\"python\", encoding=\"latin-1\")\n","ratings = pd.read_csv(\"ml-1m/ratings.dat\", sep=\"::\", header=None, engine=\"python\", encoding=\"latin-1\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KSbdp-wUlFIX"},"source":["## Preparar el conjunto de entrenamiento y el conjunto de testing"]},{"cell_type":"code","metadata":{"id":"70yEO3RWlBg2"},"source":["training_set = pd.read_csv(\"ml-100k/u1.base\", sep=\"\\t\", header=None)\n","training_set = np.array(training_set, dtype=\"int\")\n","test_set = pd.read_csv(\"ml-100k/u1.test\", sep=\"\\t\", header=None)\n","test_set = np.array(test_set, dtype=\"int\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"twATLFWTlMKM"},"source":["## Obtener el número de usuarios y de películas"]},{"cell_type":"code","metadata":{"id":"3CGpdosSlHXu"},"source":["nb_users = int(max(max(training_set[:, 0]), max(test_set[:, 0])))\n","nb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1])))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tSC4LbuvlT_I"},"source":["## Convertir los datos en un array $X_{[u,i]}$ con usuarios en $(u)$ filas y películas en $(i)$ columnas"]},{"cell_type":"code","metadata":{"id":"VmJQ-0fDlJZ4"},"source":["def convert(data):\n","    new_data = []\n","    for id_user in range(1, nb_users + 1):\n","        id_movies = data[:, 1][data[:, 0] == id_user]\n","        id_ratings = data[:, 2][data[:, 0] == id_user]\n","        ratings = np.zeros(nb_movies)\n","        ratings[id_movies - 1] = id_ratings\n","        new_data.append(list(ratings))\n","    return new_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jno3ahx9lXB3"},"source":["training_set = convert(training_set)\n","test_set = convert(test_set)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q7n1NZqylbCO"},"source":["## Convertir los datos a tensores de Torch"]},{"cell_type":"code","metadata":{"id":"qTRjUdQLlYdP"},"source":["training_set = torch.FloatTensor(training_set)\n","test_set = torch.FloatTensor(test_set)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0JAFQYBflfqd"},"source":["## Crear la arquitectura de la Red Neuronal"]},{"cell_type":"markdown","source":["https://pytorch.org/docs/stable/generated/torch.nn.Module.html\n","\n","```python\n","class Model(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(1, 20, 5)\n","        self.conv2 = nn.Conv2d(20, 20, 5)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        return F.relu(self.conv2(x))\n","```"],"metadata":{"id":"Zou5sqcVsd7I"}},{"cell_type":"code","metadata":{"id":"YbDUudP_ldDe"},"source":["class SAE(nn.Module):\n","    def __init__(self):\n","        super(SAE, self).__init__()\n","        self.fc1 = nn.Linear(nb_movies, 20)\n","        self.fc2 = nn.Linear(20, 10)\n","        self.fc3 = nn.Linear(10, 20)\n","        self.fc4 = nn.Linear(20, nb_movies)\n","        self.activation = nn.Sigmoid()\n","    def forward(self, x):\n","        x = self.activation(self.fc1(x))\n","        x = self.activation(self.fc2(x))\n","        x = self.activation(self.fc3(x))\n","        x = self.fc4(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TC6XXcLklhrU"},"source":["sae = SAE()\n","criterion = nn.MSELoss()\n","optimizer = optim.RMSprop(sae.parameters(), lr=0.01, weight_decay=0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EqRbcjMIlo1P"},"source":["## Entrenar el SAE"]},{"cell_type":"code","metadata":{"id":"gy_6yKN7lkAd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0c2489e7-de8d-4b96-dea4-48066ca0d1aa","executionInfo":{"status":"ok","timestamp":1699999217158,"user_tz":-60,"elapsed":282706,"user":{"displayName":"Jesús Mudarra Luján","userId":"18317898844326109750"}}},"source":["nb_epoch = 200\n","for epoch in range(1, nb_epoch + 1):\n","    train_loss = 0\n","    s = 0.0\n","    for id_user in range(nb_users):\n","        input = Variable(training_set[id_user]).unsqueeze(0)\n","        target = input.clone()\n","        if torch.sum(target.data > 0) > 0:\n","            output = sae.forward(input)\n","            target.require_grad = False\n","            output[target == 0] = 0\n","            loss = criterion(output, target)\n","            # la media no es sobre todas las películas, sino sobre las que realmente ha valorado\n","            mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n","            loss.backward()\n","            train_loss += np.sqrt(loss.data * mean_corrector)  # sum(errors) / n_pelis_valoradas\n","            s += 1.0\n","            optimizer.step()\n","    print(\"Epoch: \" + str(epoch) + \", Loss: \" + str(train_loss/s))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss: tensor(1.7717)\n","Epoch: 2, Loss: tensor(1.0968)\n","Epoch: 3, Loss: tensor(1.0534)\n","Epoch: 4, Loss: tensor(1.0385)\n","Epoch: 5, Loss: tensor(1.0311)\n","Epoch: 6, Loss: tensor(1.0262)\n","Epoch: 7, Loss: tensor(1.0240)\n","Epoch: 8, Loss: tensor(1.0218)\n","Epoch: 9, Loss: tensor(1.0206)\n","Epoch: 10, Loss: tensor(1.0197)\n","Epoch: 11, Loss: tensor(1.0190)\n","Epoch: 12, Loss: tensor(1.0185)\n","Epoch: 13, Loss: tensor(1.0180)\n","Epoch: 14, Loss: tensor(1.0174)\n","Epoch: 15, Loss: tensor(1.0172)\n","Epoch: 16, Loss: tensor(1.0168)\n","Epoch: 17, Loss: tensor(1.0167)\n","Epoch: 18, Loss: tensor(1.0165)\n","Epoch: 19, Loss: tensor(1.0164)\n","Epoch: 20, Loss: tensor(1.0161)\n","Epoch: 21, Loss: tensor(1.0159)\n","Epoch: 22, Loss: tensor(1.0161)\n","Epoch: 23, Loss: tensor(1.0157)\n","Epoch: 24, Loss: tensor(1.0158)\n","Epoch: 25, Loss: tensor(1.0157)\n","Epoch: 26, Loss: tensor(1.0157)\n","Epoch: 27, Loss: tensor(1.0153)\n","Epoch: 28, Loss: tensor(1.0149)\n","Epoch: 29, Loss: tensor(1.0129)\n","Epoch: 30, Loss: tensor(1.0111)\n","Epoch: 31, Loss: tensor(1.0091)\n","Epoch: 32, Loss: tensor(1.0066)\n","Epoch: 33, Loss: tensor(1.0079)\n","Epoch: 34, Loss: tensor(1.0043)\n","Epoch: 35, Loss: tensor(1.0020)\n","Epoch: 36, Loss: tensor(0.9993)\n","Epoch: 37, Loss: tensor(0.9975)\n","Epoch: 38, Loss: tensor(0.9931)\n","Epoch: 39, Loss: tensor(0.9941)\n","Epoch: 40, Loss: tensor(0.9917)\n","Epoch: 41, Loss: tensor(0.9906)\n","Epoch: 42, Loss: tensor(0.9887)\n","Epoch: 43, Loss: tensor(0.9886)\n","Epoch: 44, Loss: tensor(0.9865)\n","Epoch: 45, Loss: tensor(0.9852)\n","Epoch: 46, Loss: tensor(0.9814)\n","Epoch: 47, Loss: tensor(0.9831)\n","Epoch: 48, Loss: tensor(0.9791)\n","Epoch: 49, Loss: tensor(0.9792)\n","Epoch: 50, Loss: tensor(0.9779)\n","Epoch: 51, Loss: tensor(0.9793)\n","Epoch: 52, Loss: tensor(0.9819)\n","Epoch: 53, Loss: tensor(0.9779)\n","Epoch: 54, Loss: tensor(0.9747)\n","Epoch: 55, Loss: tensor(0.9734)\n","Epoch: 56, Loss: tensor(0.9731)\n","Epoch: 57, Loss: tensor(0.9775)\n","Epoch: 58, Loss: tensor(0.9732)\n","Epoch: 59, Loss: tensor(0.9728)\n","Epoch: 60, Loss: tensor(0.9685)\n","Epoch: 61, Loss: tensor(0.9677)\n","Epoch: 62, Loss: tensor(0.9670)\n","Epoch: 63, Loss: tensor(0.9661)\n","Epoch: 64, Loss: tensor(0.9662)\n","Epoch: 65, Loss: tensor(0.9670)\n","Epoch: 66, Loss: tensor(0.9645)\n","Epoch: 67, Loss: tensor(0.9622)\n","Epoch: 68, Loss: tensor(0.9572)\n","Epoch: 69, Loss: tensor(0.9616)\n","Epoch: 70, Loss: tensor(0.9648)\n","Epoch: 71, Loss: tensor(0.9663)\n","Epoch: 72, Loss: tensor(0.9560)\n","Epoch: 73, Loss: tensor(0.9560)\n","Epoch: 74, Loss: tensor(0.9544)\n","Epoch: 75, Loss: tensor(0.9558)\n","Epoch: 76, Loss: tensor(0.9576)\n","Epoch: 77, Loss: tensor(0.9551)\n","Epoch: 78, Loss: tensor(0.9530)\n","Epoch: 79, Loss: tensor(0.9545)\n","Epoch: 80, Loss: tensor(0.9511)\n","Epoch: 81, Loss: tensor(0.9514)\n","Epoch: 82, Loss: tensor(0.9492)\n","Epoch: 83, Loss: tensor(0.9491)\n","Epoch: 84, Loss: tensor(0.9460)\n","Epoch: 85, Loss: tensor(0.9473)\n","Epoch: 86, Loss: tensor(0.9445)\n","Epoch: 87, Loss: tensor(0.9467)\n","Epoch: 88, Loss: tensor(0.9436)\n","Epoch: 89, Loss: tensor(0.9448)\n","Epoch: 90, Loss: tensor(0.9411)\n","Epoch: 91, Loss: tensor(0.9431)\n","Epoch: 92, Loss: tensor(0.9401)\n","Epoch: 93, Loss: tensor(0.9419)\n","Epoch: 94, Loss: tensor(0.9389)\n","Epoch: 95, Loss: tensor(0.9406)\n","Epoch: 96, Loss: tensor(0.9378)\n","Epoch: 97, Loss: tensor(0.9390)\n","Epoch: 98, Loss: tensor(0.9365)\n","Epoch: 99, Loss: tensor(0.9384)\n","Epoch: 100, Loss: tensor(0.9359)\n","Epoch: 101, Loss: tensor(0.9369)\n","Epoch: 102, Loss: tensor(0.9349)\n","Epoch: 103, Loss: tensor(0.9362)\n","Epoch: 104, Loss: tensor(0.9344)\n","Epoch: 105, Loss: tensor(0.9350)\n","Epoch: 106, Loss: tensor(0.9337)\n","Epoch: 107, Loss: tensor(0.9345)\n","Epoch: 108, Loss: tensor(0.9329)\n","Epoch: 109, Loss: tensor(0.9327)\n","Epoch: 110, Loss: tensor(0.9319)\n","Epoch: 111, Loss: tensor(0.9327)\n","Epoch: 112, Loss: tensor(0.9315)\n","Epoch: 113, Loss: tensor(0.9311)\n","Epoch: 114, Loss: tensor(0.9303)\n","Epoch: 115, Loss: tensor(0.9299)\n","Epoch: 116, Loss: tensor(0.9300)\n","Epoch: 117, Loss: tensor(0.9306)\n","Epoch: 118, Loss: tensor(0.9301)\n","Epoch: 119, Loss: tensor(0.9303)\n","Epoch: 120, Loss: tensor(0.9288)\n","Epoch: 121, Loss: tensor(0.9292)\n","Epoch: 122, Loss: tensor(0.9280)\n","Epoch: 123, Loss: tensor(0.9291)\n","Epoch: 124, Loss: tensor(0.9274)\n","Epoch: 125, Loss: tensor(0.9284)\n","Epoch: 126, Loss: tensor(0.9270)\n","Epoch: 127, Loss: tensor(0.9275)\n","Epoch: 128, Loss: tensor(0.9267)\n","Epoch: 129, Loss: tensor(0.9274)\n","Epoch: 130, Loss: tensor(0.9263)\n","Epoch: 131, Loss: tensor(0.9267)\n","Epoch: 132, Loss: tensor(0.9255)\n","Epoch: 133, Loss: tensor(0.9262)\n","Epoch: 134, Loss: tensor(0.9251)\n","Epoch: 135, Loss: tensor(0.9258)\n","Epoch: 136, Loss: tensor(0.9251)\n","Epoch: 137, Loss: tensor(0.9254)\n","Epoch: 138, Loss: tensor(0.9246)\n","Epoch: 139, Loss: tensor(0.9251)\n","Epoch: 140, Loss: tensor(0.9239)\n","Epoch: 141, Loss: tensor(0.9245)\n","Epoch: 142, Loss: tensor(0.9233)\n","Epoch: 143, Loss: tensor(0.9239)\n","Epoch: 144, Loss: tensor(0.9227)\n","Epoch: 145, Loss: tensor(0.9234)\n","Epoch: 146, Loss: tensor(0.9223)\n","Epoch: 147, Loss: tensor(0.9231)\n","Epoch: 148, Loss: tensor(0.9221)\n","Epoch: 149, Loss: tensor(0.9225)\n","Epoch: 150, Loss: tensor(0.9216)\n","Epoch: 151, Loss: tensor(0.9221)\n","Epoch: 152, Loss: tensor(0.9212)\n","Epoch: 153, Loss: tensor(0.9215)\n","Epoch: 154, Loss: tensor(0.9204)\n","Epoch: 155, Loss: tensor(0.9209)\n","Epoch: 156, Loss: tensor(0.9200)\n","Epoch: 157, Loss: tensor(0.9205)\n","Epoch: 158, Loss: tensor(0.9196)\n","Epoch: 159, Loss: tensor(0.9199)\n","Epoch: 160, Loss: tensor(0.9193)\n","Epoch: 161, Loss: tensor(0.9197)\n","Epoch: 162, Loss: tensor(0.9190)\n","Epoch: 163, Loss: tensor(0.9193)\n","Epoch: 164, Loss: tensor(0.9185)\n","Epoch: 165, Loss: tensor(0.9187)\n","Epoch: 166, Loss: tensor(0.9182)\n","Epoch: 167, Loss: tensor(0.9185)\n","Epoch: 168, Loss: tensor(0.9179)\n","Epoch: 169, Loss: tensor(0.9180)\n","Epoch: 170, Loss: tensor(0.9177)\n","Epoch: 171, Loss: tensor(0.9176)\n","Epoch: 172, Loss: tensor(0.9171)\n","Epoch: 173, Loss: tensor(0.9175)\n","Epoch: 174, Loss: tensor(0.9168)\n","Epoch: 175, Loss: tensor(0.9171)\n","Epoch: 176, Loss: tensor(0.9165)\n","Epoch: 177, Loss: tensor(0.9168)\n","Epoch: 178, Loss: tensor(0.9162)\n","Epoch: 179, Loss: tensor(0.9164)\n","Epoch: 180, Loss: tensor(0.9158)\n","Epoch: 181, Loss: tensor(0.9160)\n","Epoch: 182, Loss: tensor(0.9158)\n","Epoch: 183, Loss: tensor(0.9160)\n","Epoch: 184, Loss: tensor(0.9154)\n","Epoch: 185, Loss: tensor(0.9155)\n","Epoch: 186, Loss: tensor(0.9153)\n","Epoch: 187, Loss: tensor(0.9153)\n","Epoch: 188, Loss: tensor(0.9149)\n","Epoch: 189, Loss: tensor(0.9148)\n","Epoch: 190, Loss: tensor(0.9146)\n","Epoch: 191, Loss: tensor(0.9147)\n","Epoch: 192, Loss: tensor(0.9144)\n","Epoch: 193, Loss: tensor(0.9141)\n","Epoch: 194, Loss: tensor(0.9138)\n","Epoch: 195, Loss: tensor(0.9139)\n","Epoch: 196, Loss: tensor(0.9139)\n","Epoch: 197, Loss: tensor(0.9138)\n","Epoch: 198, Loss: tensor(0.9135)\n","Epoch: 199, Loss: tensor(0.9135)\n","Epoch: 200, Loss: tensor(0.9131)\n"]}]},{"cell_type":"markdown","metadata":{"id":"ENHGLCyiluJn"},"source":["## Evaluar el conjunto de test en nuestro SAE"]},{"cell_type":"code","metadata":{"id":"UAL0ZZOhlruw"},"source":["test_loss = 0\n","s = 0.0\n","for id_user in range(nb_users):\n","    input = Variable(training_set[id_user]).unsqueeze(0)\n","    target = Variable(test_set[id_user]).unsqueeze(0)\n","    if torch.sum(target.data > 0) > 0:\n","        output = sae.forward(input)\n","        target.require_grad = False\n","        output[target == 0] = 0\n","        loss = criterion(output, target)\n","        # la media no es sobre todas las películas, sino sobre las que realmente ha valorado\n","        mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n","        test_loss += np.sqrt(loss.data * mean_corrector)  # sum(errors) / n_pelis_valoradas\n","        s += 1.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Quy4q1UFlwfF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"11fdc761-6516-444e-89a5-5e28fe93338a","executionInfo":{"status":"ok","timestamp":1699999217568,"user_tz":-60,"elapsed":9,"user":{"displayName":"Jesús Mudarra Luján","userId":"18317898844326109750"}}},"source":["print(\"Test Loss: \" + str(test_loss/s))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: tensor(0.9471)\n"]}]}]}